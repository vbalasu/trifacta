{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trifacta\n",
    "\n",
    "1. Connect to a remote Trifacta instance\n",
    "2. Run jobs\n",
    "3. Send and receive files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install pywebhdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, json, time, datetime, io\n",
    "from pywebhdfs.webhdfs import PyWebHdfsClient\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "class Trifacta:\n",
    "    def __init__(self, trifacta_base_url, user_id, password):\n",
    "        \"\"\"Example: t = Trifacta('https://partnerdemo.trifacta.net', 'guest_user', 'guest_password')\"\"\"\n",
    "        self.trifacta_base_url = trifacta_base_url\n",
    "        self.user_id = user_id\n",
    "        self.password = password\n",
    "    def get_job_status(self, job_group_id):\n",
    "        response = requests.get(self.trifacta_base_url + '/v3/jobGroups/{0}/status'.format(job_group_id), auth=('admin@trifacta.local', 'Tr1f@ct@1!'))\n",
    "        return json.loads(response.text)\n",
    "    def run_job(self, wrangled_dataset_id):\n",
    "        \"\"\"Get the wrangled_dataset_id from your browser's URL when editing the recipe\"\"\"\n",
    "        request_body = {\"wrangledDataset\": {\"id\": wrangled_dataset_id }}\n",
    "        print('About to run job', flush=True)\n",
    "        response = requests.post(self.trifacta_base_url + '/v3/jobGroups', auth=(self.user_id, self.password), json=request_body)\n",
    "        response_obj = json.loads(response.text)\n",
    "        print(response_obj, flush=True)\n",
    "        self.job_group_id = response_obj['jobgroupId']\n",
    "        job_status = self.get_job_status(self.job_group_id)\n",
    "        while job_status != 'Complete':\n",
    "            print(datetime.datetime.today(), job_status, flush=True)\n",
    "            time.sleep(5)\n",
    "            job_status = self.get_job_status(self.job_group_id)\n",
    "        print(datetime.datetime.today(), job_status, flush=True)\n",
    "        return True\n",
    "    def get_file_contents(self, hdfs_path, user_name='trifacta', httpfs_port='14000'):\n",
    "        hdfs = PyWebHdfsClient(host=urlparse(self.trifacta_base_url).netloc,port=httpfs_port, user_name=user_name)\n",
    "        return hdfs.read_file(hdfs_path).decode('utf-8')\n",
    "    def get_dataframe(self, hdfs_path_to_csv):\n",
    "        csv_string = self.get_file_contents(hdfs_path_to_csv)\n",
    "        return pd.read_csv(io.StringIO(csv_string))\n",
    "    def put_file_contents(self, hdfs_path, file_contents, user_name='trifacta', httpfs_port='14000'):\n",
    "        hdfs = PyWebHdfsClient(host=urlparse(self.trifacta_base_url).netloc,port=httpfs_port, user_name=user_name)\n",
    "        hdfs.create_file(hdfs_path, file_contents, overwrite=True)\n",
    "        return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
